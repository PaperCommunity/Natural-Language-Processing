## 其他任务

* [《Improving a Neural Semantic Parser by Counterfactual Learning from Human Bandit Feedback》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 德国海德堡大学计算语言学系。他们设计了一个收集人类情感解析的界面，使用人类匪徒的反事实学习提升情感解析的性能
>>>>>>> Stashed changes

* [《Analogical Reasoning on Chinese Morphological and Semantic Relations》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 类比推理法可以有效地抓取语言规律。北京师范大学中文信息研究所提出面向中文的类比推理任务。该任务包含68个隐含形态关系和28个明确语义关系。基于该任务，作者构建了一个包含17813个问题的数据集，并拓展了向量表示、文本特征和语料集在类比推理任务上的影响。实验证明CA8是一个建言中文词向量的优秀语料库
>>>>>>> Stashed changes

* [《Cross-Target Stance Classification with Self-Attention Networks》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 立场分类是根据用户的话来判该用户对该主题的立场（态度）。通常立场分类只能在特定目标源（即主题）上训练特定分类器，鲁棒性。本文提出了一个新的模型在增强鲁棒性。该模型可以发掘并共享相关目标间的信息，这有效地提升了特定场景下的泛化性。
>>>>>>> Stashed changes

* [《Straight to the Tree: Constituency Parsing with Neural Syntactic Distance》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 文章提出constituency parsing（一种句法分析）方案。相比于传统的shift-reduce parsing，该方法没有复合错误的潜在问题，同时更快，更容易并行化。
>>>>>>> Stashed changes
