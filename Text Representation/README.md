## 文本表示

* [《Transformation Networks for Target-Oriented Sentiment Classification》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 香港大学和腾讯AI实验室的学者通过re-examining Attention的缺点和CNN的问题，提出一个新模型。该模型使用CNN从BLSTM特征上提取特征。在两层网络中间，他们提出了一个部件生成词的表示同时包含一个保存RNN输出的文本信息的机制。
>>>>>>> Stashed changes

* [《Chinese NER Using Lattice LSTM》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 使用Lattice-lstm将字生成词进行命名实体识别。 
>>>>>>> Stashed changes

* [《Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: embedding方法是一个转移关系建模的方法（如order embedding）。OE是需要确定的知识库，受限于queries的表示和利用不确定概率和学习。OE的概率拓展在提供了一些指示概率的修正但缺乏发现现实世界中负相关的能力。本文提出构建了box latice 和跟随概率测量的方法来抓取反相关，甚至互斥的概念，从而解决broad class of models 不能抓取负关系的问题。该方法通过任意概念级丰富了联合query、条件query，并从他们中间习得非确定性矫正。实验证明该方法在Flickr和WordNet的蕴含图上有很好的效果
>>>>>>> Stashed changes

* [《Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: embedding方法是一个转移关系建模的方法（如order embedding）。OE是需要确定的知识库，受限于queries的表示和利用不确定概率和学习。OE的概率拓展在提供了一些指示概率的修正但缺乏发现现实世界中负相关的能力。本文提出构建了box latice 和跟随概率测量的方法来抓取反相关，甚至互斥的概念，从而解决broad class of models 不能抓取负关系的问题。该方法通过任意概念级丰富了联合query、条件query，并从他们中间习得非确定性矫正。实验证明该方法在Flickr和WordNet的蕴含图上有很好的效果
>>>>>>> Stashed changes

* [《Graph-to-Sequence Learning using Gated Graph Neural Networks	2018	ACL	A	方法-表示/图模型	许多NLP任务可以被定义为图-序列问题。先前的模型依赖于线性化与启发式和循环网络。本文提出一个新的模型将图中的结构信息编码。该模型将GGNN与transformation结合，使节点和边具有它们的表示，以解决先前工作中参数爆炸的问题。实验证明模型效果极好》](https://github.com/PaperCommunity/Reinforcement-Learning/tree/master/ImitationLearning/Playing%20hard%20exploration%20games%20by%20watching%20YouTube)
<<<<<<< Updated upstream
  * **update**: 2019.02.01
  * **author**: [SPY-Ming](https://github.com/SPY-Ming)
  * **overview**: 许多NLP任务可以被定义为图-序列问题。先前的模型依赖于线性化与启发式和循环网络。本文提出一个新的模型将图中的结构信息编码。该模型将GGNN与transformation结合，使节点和边具有它们的表示，以解决先前工作中参数爆炸的问题。实验证明模型效果极好
>>>>>>> Stashed changes

